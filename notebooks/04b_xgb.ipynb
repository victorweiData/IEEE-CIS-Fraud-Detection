{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGB\n",
    "import os, gc, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes -> train: (590540, 293) test: (506691, 292)\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"../data/processed\"\n",
    "trainX = pd.read_csv(f\"{DATA_DIR}/IEEE_Train.csv\")\n",
    "y      = pd.read_csv(f\"{DATA_DIR}/IEEE_Target.csv\")   # TransactionID, isFraud\n",
    "testX  = pd.read_csv(f\"{DATA_DIR}/IEEE_Test.csv\")\n",
    "\n",
    "train = trainX.merge(y, on=\"TransactionID\", how=\"left\")\n",
    "assert \"isFraud\" in train.columns\n",
    "print(\"Shapes -> train:\", train.shape, \"test:\", testX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "USING GROUPKFOLD WITH DT_M\n",
      "==================================================\n",
      "Created 6 folds using GroupKFold\n",
      "Fold 0 withholding month 12\n",
      " rows of train = 453219, rows of holdout = 137321\n",
      "Fold 1 withholding month 15\n",
      " rows of train = 488908, rows of holdout = 101632\n",
      "Fold 2 withholding month 13\n",
      " rows of train = 497955, rows of holdout = 92585\n",
      "Fold 3 withholding month 17\n",
      " rows of train = 501214, rows of holdout = 89326\n",
      "Fold 4 withholding month 14\n",
      " rows of train = 504519, rows of holdout = 86021\n",
      "Fold 5 withholding month 16\n",
      " rows of train = 506885, rows of holdout = 83655\n",
      "\n",
      "Overall fraud rate: 0.0350 (3.50%)\n"
     ]
    }
   ],
   "source": [
    "# Use GroupKFold\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"USING GROUPKFOLD WITH DT_M\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Check if DT_M column exists\n",
    "if 'DT_M' not in train.columns:\n",
    "    print(\"WARNING: DT_M column not found. Creating from day column...\")\n",
    "    def add_month_ix_from_day(df, day_col=\"day\", days_per_month=30):\n",
    "        if day_col not in df.columns:\n",
    "            raise KeyError(\"Expected a 'day' column (present in this dataset).\")\n",
    "        d0 = int(df[day_col].min())\n",
    "        return ((df[day_col] - d0) // days_per_month).astype(\"int16\")\n",
    "    \n",
    "    train[\"DT_M\"] = add_month_ix_from_day(train, day_col=\"day\")\n",
    "\n",
    "# Use GroupKFold\n",
    "skf = GroupKFold(n_splits=6)\n",
    "folds = list(skf.split(train, train[\"isFraud\"], groups=train['DT_M']))\n",
    "\n",
    "print(f\"Created {len(folds)} folds using GroupKFold\")\n",
    "\n",
    "# Print fold information like the winner\n",
    "for i, (tr_idx, va_idx) in enumerate(folds):\n",
    "    month = train.iloc[va_idx]['DT_M'].iloc[0]\n",
    "    print(f'Fold {i} withholding month {month}')\n",
    "    print(f' rows of train = {len(tr_idx)}, rows of holdout = {len(va_idx)}')\n",
    "\n",
    "# Overall fraud rate\n",
    "overall_fraud_rate = train['isFraud'].mean()\n",
    "print(f\"\\nOverall fraud rate: {overall_fraud_rate:.4f} ({overall_fraud_rate*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOW USING THE FOLLOWING 263 FEATURES.\n",
      "['TransactionAmt', 'ProductCD', 'card1', 'card2', 'card3', 'card5', 'card6', 'addr1', 'addr2', 'dist1', 'dist2', 'P_emaildomain', 'R_emaildomain', 'C1', 'C2', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11', 'C12', 'C13', 'C14', 'D1', 'D2', 'D3', 'D4', 'D5', 'D10', 'D11', 'D15', 'M1', 'M2', 'M3', 'M4', 'M6', 'M7', 'M8', 'M9', 'V1', 'V3', 'V4', 'V6', 'V8', 'V11', 'V13', 'V14', 'V17', 'V20', 'V23', 'V26', 'V27', 'V30', 'V36', 'V37', 'V40', 'V41', 'V44', 'V47', 'V48', 'V54', 'V56', 'V59', 'V62', 'V65', 'V67', 'V68', 'V70', 'V76', 'V78', 'V80', 'V82', 'V86', 'V88', 'V89', 'V91', 'V107', 'V108', 'V111', 'V115', 'V117', 'V120', 'V121', 'V123', 'V124', 'V127', 'V129', 'V130', 'V136', 'V138', 'V139', 'V142', 'V147', 'V156', 'V160', 'V162', 'V165', 'V166', 'V169', 'V171', 'V173', 'V175', 'V176', 'V178', 'V180', 'V182', 'V185', 'V187', 'V188', 'V198', 'V203', 'V205', 'V207', 'V209', 'V210', 'V215', 'V218', 'V220', 'V221', 'V223', 'V224', 'V226', 'V228', 'V229', 'V234', 'V235', 'V238', 'V240', 'V250', 'V252', 'V253', 'V257', 'V258', 'V260', 'V261', 'V264', 'V266', 'V267', 'V271', 'V274', 'V277', 'V281', 'V283', 'V284', 'V285', 'V286', 'V289', 'V291', 'V294', 'V296', 'V297', 'V301', 'V303', 'V305', 'V307', 'V309', 'V310', 'V314', 'V320', 'id_01', 'id_02', 'id_03', 'id_04', 'id_05', 'id_06', 'id_09', 'id_10', 'id_11', 'id_12', 'id_13', 'id_15', 'id_16', 'id_17', 'id_18', 'id_19', 'id_20', 'id_28', 'id_29', 'id_31', 'id_35', 'id_36', 'id_37', 'id_38', 'DeviceType', 'DeviceInfo', 'cents', 'addr1_FE', 'card1_FE', 'card2_FE', 'card3_FE', 'P_emaildomain_FE', 'card1_addr1', 'card1_addr1_P_emaildomain', 'card1_addr1_FE', 'card1_addr1_P_emaildomain_FE', 'TransactionAmt_card1_mean', 'TransactionAmt_card1_std', 'TransactionAmt_card1_addr1_mean', 'TransactionAmt_card1_addr1_std', 'TransactionAmt_card1_addr1_P_emaildomain_mean', 'TransactionAmt_card1_addr1_P_emaildomain_std', 'D9_card1_mean', 'D9_card1_std', 'D9_card1_addr1_mean', 'D9_card1_addr1_std', 'D9_card1_addr1_P_emaildomain_mean', 'D9_card1_addr1_P_emaildomain_std', 'D11_card1_mean', 'D11_card1_std', 'D11_card1_addr1_mean', 'D11_card1_addr1_std', 'D11_card1_addr1_P_emaildomain_mean', 'D11_card1_addr1_P_emaildomain_std', 'uid_FE', 'TransactionAmt_uid_mean', 'TransactionAmt_uid_std', 'D4_uid_mean', 'D4_uid_std', 'D9_uid_mean', 'D9_uid_std', 'D10_uid_mean', 'D10_uid_std', 'D15_uid_mean', 'D15_uid_std', 'C1_uid_mean', 'C2_uid_mean', 'C4_uid_mean', 'C5_uid_mean', 'C6_uid_mean', 'C7_uid_mean', 'C8_uid_mean', 'C9_uid_mean', 'C10_uid_mean', 'C11_uid_mean', 'C12_uid_mean', 'C13_uid_mean', 'C14_uid_mean', 'M1_uid_mean', 'M2_uid_mean', 'M3_uid_mean', 'M4_uid_mean', 'M5_uid_mean', 'M6_uid_mean', 'M7_uid_mean', 'M8_uid_mean', 'M9_uid_mean', 'uid_P_emaildomain_ct', 'uid_dist1_ct', 'uid_DT_M_ct', 'uid_id_02_ct', 'uid_cents_ct', 'C14_uid_std', 'uid_C13_ct', 'uid_V314_ct', 'uid_V127_ct', 'uid_V136_ct', 'uid_V309_ct', 'uid_V307_ct', 'uid_V320_ct', 'outsider15']\n"
     ]
    }
   ],
   "source": [
    "# Feature selection\n",
    "drop_time = ['TransactionDT']                                # time index\n",
    "drop_leaky = ['D6','D7','D8','D9','D12','D13','D14']         # leaky/time-variant set\n",
    "drop_unstable = ['C3','M5','id_08','id_33',                  # failed time consistency\n",
    "                 'card4','id_07','id_14','id_21','id_30','id_32','id_34'] \\\n",
    "                + [f'id_{x}' for x in range(22,28)]\n",
    "\n",
    "DROP_COLS = set(drop_time + drop_leaky + drop_unstable)\n",
    "\n",
    "EXCLUDE_COLS = {\n",
    "    'TransactionID',  # id\n",
    "    'uid',            # raw identifier -> exclude\n",
    "    'isFraud',        # target\n",
    "    # exclude time indices\n",
    "    'DT_M', 'day'\n",
    "}\n",
    "\n",
    "# Build FEATURES from train, enforce presence in test as well\n",
    "base = [c for c in train.columns if c not in EXCLUDE_COLS]\n",
    "FEATURES = [c for c in base if c not in DROP_COLS]\n",
    "# keep only columns that exist in BOTH train and test (prevents surprises)\n",
    "FEATURES = [c for c in FEATURES if c in testX.columns]\n",
    "\n",
    "print(f'NOW USING THE FOLLOWING {len(FEATURES)} FEATURES.')\n",
    "print(FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost parameters (Winner's approach):\n",
      "{\n",
      "  \"n_estimators\": 5000,\n",
      "  \"max_depth\": 12,\n",
      "  \"learning_rate\": 0.02,\n",
      "  \"subsample\": 0.8,\n",
      "  \"colsample_bytree\": 0.4,\n",
      "  \"missing\": -1,\n",
      "  \"eval_metric\": \"auc\",\n",
      "  \"tree_method\": \"hist\",\n",
      "  \"random_state\": 42,\n",
      "  \"n_jobs\": -1,\n",
      "  \"early_stopping_rounds\": 200,\n",
      "  \"verbosity\": 1\n",
      "}\n",
      "\n",
      "==================================================\n",
      "TRAINING XGBOOST WITH GROUPKFOLD\n",
      "==================================================\n",
      "\n",
      "Fold 0 withholding month 12\n",
      " rows of train = 453219, rows of holdout = 137321\n",
      "[0]\tvalidation_0-auc:0.80381\n",
      "[100]\tvalidation_0-auc:0.91492\n",
      "[200]\tvalidation_0-auc:0.92219\n",
      "[300]\tvalidation_0-auc:0.92619\n",
      "[400]\tvalidation_0-auc:0.92738\n",
      "[500]\tvalidation_0-auc:0.92766\n",
      "[600]\tvalidation_0-auc:0.92738\n",
      "[646]\tvalidation_0-auc:0.92736\n",
      "Fold 0 AUC: 0.9277, Best iteration: 447\n",
      "\n",
      "Fold 1 withholding month 15\n",
      " rows of train = 488908, rows of holdout = 101632\n",
      "[0]\tvalidation_0-auc:0.85161\n",
      "[100]\tvalidation_0-auc:0.94673\n",
      "[200]\tvalidation_0-auc:0.95586\n",
      "[300]\tvalidation_0-auc:0.95882\n",
      "[400]\tvalidation_0-auc:0.95977\n",
      "[500]\tvalidation_0-auc:0.96019\n",
      "[600]\tvalidation_0-auc:0.96045\n",
      "[700]\tvalidation_0-auc:0.96031\n",
      "[800]\tvalidation_0-auc:0.96011\n",
      "[857]\tvalidation_0-auc:0.96008\n",
      "Fold 1 AUC: 0.9605, Best iteration: 657\n",
      "\n",
      "Fold 2 withholding month 13\n",
      " rows of train = 497955, rows of holdout = 92585\n",
      "[0]\tvalidation_0-auc:0.82450\n",
      "[100]\tvalidation_0-auc:0.94114\n",
      "[200]\tvalidation_0-auc:0.95284\n",
      "[300]\tvalidation_0-auc:0.95720\n",
      "[400]\tvalidation_0-auc:0.95862\n",
      "[500]\tvalidation_0-auc:0.95904\n",
      "[600]\tvalidation_0-auc:0.95895\n",
      "[689]\tvalidation_0-auc:0.95902\n",
      "Fold 2 AUC: 0.9592, Best iteration: 489\n",
      "\n",
      "Fold 3 withholding month 17\n",
      " rows of train = 501214, rows of holdout = 89326\n",
      "[0]\tvalidation_0-auc:0.82815\n",
      "[100]\tvalidation_0-auc:0.93796\n",
      "[200]\tvalidation_0-auc:0.94863\n",
      "[300]\tvalidation_0-auc:0.95217\n",
      "[400]\tvalidation_0-auc:0.95294\n",
      "[500]\tvalidation_0-auc:0.95309\n",
      "[600]\tvalidation_0-auc:0.95303\n",
      "[700]\tvalidation_0-auc:0.95271\n",
      "[761]\tvalidation_0-auc:0.95259\n",
      "Fold 3 AUC: 0.9533, Best iteration: 562\n",
      "\n",
      "Fold 4 withholding month 14\n",
      " rows of train = 504519, rows of holdout = 86021\n",
      "[0]\tvalidation_0-auc:0.84228\n",
      "[100]\tvalidation_0-auc:0.95517\n",
      "[200]\tvalidation_0-auc:0.96274\n",
      "[300]\tvalidation_0-auc:0.96461\n",
      "[400]\tvalidation_0-auc:0.96488\n",
      "[500]\tvalidation_0-auc:0.96496\n",
      "[600]\tvalidation_0-auc:0.96472\n",
      "[693]\tvalidation_0-auc:0.96463\n",
      "Fold 4 AUC: 0.9650, Best iteration: 494\n",
      "\n",
      "Fold 5 withholding month 16\n",
      " rows of train = 506885, rows of holdout = 83655\n",
      "[0]\tvalidation_0-auc:0.82615\n",
      "[100]\tvalidation_0-auc:0.95122\n",
      "[200]\tvalidation_0-auc:0.96293\n",
      "[300]\tvalidation_0-auc:0.96718\n",
      "[400]\tvalidation_0-auc:0.96870\n",
      "[500]\tvalidation_0-auc:0.96920\n",
      "[600]\tvalidation_0-auc:0.96970\n",
      "[700]\tvalidation_0-auc:0.96995\n",
      "[800]\tvalidation_0-auc:0.96994\n",
      "[900]\tvalidation_0-auc:0.96981\n",
      "[951]\tvalidation_0-auc:0.96972\n",
      "Fold 5 AUC: 0.9701, Best iteration: 752\n",
      "####################\n",
      "XGB OOF CV = 0.9551\n",
      "\n",
      "==================================================\n",
      "XGBOOST CV RESULTS\n",
      "==================================================\n",
      "Fold AUCs: [0.9277 0.9605 0.9592 0.9533 0.965  0.9701]\n",
      "Weighted mean AUC: 0.9536\n",
      "OOF AUC: 0.9551\n"
     ]
    }
   ],
   "source": [
    "# XGBoost parameters\n",
    "xgb_params = {\n",
    "    'n_estimators': 5000,\n",
    "    'max_depth': 12, \n",
    "    'learning_rate': 0.02, \n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.4,\n",
    "    'missing': -1,\n",
    "    'eval_metric': 'auc',\n",
    "    'tree_method': 'hist',\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1,\n",
    "    'early_stopping_rounds' : 200,\n",
    "    'verbosity': 1\n",
    "}\n",
    "\n",
    "print(\"XGBoost parameters (Winner's approach):\")\n",
    "print(json.dumps(xgb_params, indent=2))\n",
    "\n",
    "# Initialize storage\n",
    "models = []\n",
    "oof = np.zeros(len(train), dtype=float)\n",
    "fold_scores, fold_sizes = [], []\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TRAINING XGBOOST WITH GROUPKFOLD\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for k, (tr_idx, va_idx) in enumerate(folds):\n",
    "    month = train.iloc[va_idx]['DT_M'].iloc[0]\n",
    "    print(f'\\nFold {k} withholding month {month}')\n",
    "    print(f' rows of train = {len(tr_idx)}, rows of holdout = {len(va_idx)}')\n",
    "    \n",
    "    # Prepare data\n",
    "    X_tr, y_tr = train.iloc[tr_idx][FEATURES], train.iloc[tr_idx][\"isFraud\"]\n",
    "    X_va, y_va = train.iloc[va_idx][FEATURES], train.iloc[va_idx][\"isFraud\"]\n",
    "    \n",
    "    # Create XGBoost classifier\n",
    "    clf = xgb.XGBClassifier(**xgb_params)\n",
    "    \n",
    "    # Fit with early stopping like the winner\n",
    "    h = clf.fit(\n",
    "        X_tr, y_tr,\n",
    "        eval_set=[(X_va, y_va)],\n",
    "        verbose=100\n",
    "    )\n",
    "    \n",
    "    # Predict validation set\n",
    "    preds = clf.predict_proba(X_va)[:, 1]  # Get probability of class 1\n",
    "    oof[va_idx] = preds\n",
    "    \n",
    "    # Calculate AUC\n",
    "    auc = roc_auc_score(y_va, preds)\n",
    "    fold_scores.append(auc)\n",
    "    fold_sizes.append(len(va_idx))\n",
    "    \n",
    "    print(f\"Fold {k} AUC: {auc:.4f}, Best iteration: {clf.best_iteration}\")\n",
    "    \n",
    "    # Store model\n",
    "    models.append(clf)\n",
    "    \n",
    "    # Save individual fold model\n",
    "    os.makedirs(\"xgboost_artifacts\", exist_ok=True)\n",
    "    clf.save_model(f\"xgboost_artifacts/xgb_fold{k}.json\")\n",
    "    \n",
    "    # Memory cleanup like winner\n",
    "    del h, clf, X_tr, y_tr, X_va, y_va\n",
    "    x = gc.collect()\n",
    "\n",
    "# Calculate overall performance\n",
    "fold_scores = np.array(fold_scores, dtype=float)\n",
    "weights = np.array(fold_sizes, dtype=float) / np.sum(fold_sizes)\n",
    "weighted_cv = float(np.sum(fold_scores * weights))\n",
    "oof_mask = oof != 0\n",
    "oof_auc = roc_auc_score(train[\"isFraud\"], oof)\n",
    "\n",
    "print('#'*20)\n",
    "print(f'XGB OOF CV = {oof_auc:.4f}')\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"XGBOOST CV RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(\"Fold AUCs:\", np.round(fold_scores, 4))\n",
    "print(\"Weighted mean AUC:\", f\"{weighted_cv:.4f}\")\n",
    "print(\"OOF AUC:\", f\"{oof_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "GENERATING SUBMISSION\n",
      "==============================\n",
      "Fold 0 test predictions: mean=0.0277, std=0.1120\n",
      "Fold 1 test predictions: mean=0.0243, std=0.1119\n",
      "Fold 2 test predictions: mean=0.0268, std=0.1129\n",
      "Fold 3 test predictions: mean=0.0257, std=0.1140\n",
      "Fold 4 test predictions: mean=0.0266, std=0.1120\n",
      "Fold 5 test predictions: mean=0.0234, std=0.1121\n",
      "Final averaged predictions: mean=0.0258, std=0.1116\n",
      "Saved submission: submissions/submission_xgb_groupkfold_cv0.9551.csv\n",
      "\n",
      "==================================================\n",
      "KEY CHANGES MADE TO MATCH WINNER:\n",
      "==================================================\n",
      "1. ✅ Used GroupKFold(n_splits=6) instead of expanding folds\n",
      "2. ✅ Increased n_estimators from 2000 to 5000\n",
      "3. ✅ Used groups=train['DT_M'] for temporal validation\n",
      "4. ✅ Only used validation set in eval_set (not train set)\n",
      "5. ✅ Calculated OOF AUC on all samples\n",
      "6. ✅ Added proper memory cleanup\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# GENERATE TEST PREDICTIONS\n",
    "# ============================================\n",
    "\n",
    "def coerce_transaction_id(s: pd.Series) -> pd.Series:\n",
    "    if pd.api.types.is_integer_dtype(s): \n",
    "        return s.astype(\"int64\")\n",
    "    if pd.api.types.is_float_dtype(s):   \n",
    "        return s.round().astype(\"int64\")\n",
    "    if pd.api.types.is_string_dtype(s):\n",
    "        s2 = s.str.replace(r\"\\.0$\", \"\", regex=True)\n",
    "        return pd.to_numeric(s2, errors=\"raise\").astype(\"int64\")\n",
    "    return pd.to_numeric(s, errors=\"raise\").astype(\"int64\")\n",
    "\n",
    "if \"TransactionID\" in testX.columns:\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(\"GENERATING SUBMISSION\")\n",
    "    print(\"=\"*30)\n",
    "    \n",
    "    test_id = coerce_transaction_id(testX[\"TransactionID\"])\n",
    "    \n",
    "    # Average predictions like winner (they used preds += clf.predict_proba(X_test[cols])[:,1]/skf.n_splits)\n",
    "    test_preds = np.zeros(len(testX))\n",
    "    \n",
    "    for i, model in enumerate(models):\n",
    "        fold_preds = model.predict_proba(testX[FEATURES])[:, 1]\n",
    "        test_preds += fold_preds / len(models)  # Average like winner\n",
    "        print(f\"Fold {i} test predictions: mean={fold_preds.mean():.4f}, std={fold_preds.std():.4f}\")\n",
    "    \n",
    "    print(f\"Final averaged predictions: mean={test_preds.mean():.4f}, std={test_preds.std():.4f}\")\n",
    "    \n",
    "    # Create submission\n",
    "    sub = pd.DataFrame({\"TransactionID\": test_id, \"isFraud\": test_preds})\n",
    "    os.makedirs(\"submissions\", exist_ok=True)\n",
    "    out_path = f\"submissions/submission_xgb_groupkfold_cv{oof_auc:.4f}.csv\"\n",
    "    sub.to_csv(out_path, index=False)\n",
    "    print(f\"Saved submission: {out_path}\")\n",
    "    \n",
    "    # Save artifacts for ensemble\n",
    "    np.save(\"xgboost_artifacts/xgb_oof_predictions.npy\", oof)\n",
    "    np.save(\"xgboost_artifacts/xgb_test_predictions.npy\", test_preds)\n",
    "    \n",
    "    # Save model metadata\n",
    "    model_metadata = {\n",
    "        \"model_type\": \"xgboost_groupkfold\",\n",
    "        \"oof_auc\": oof_auc,\n",
    "        \"weighted_cv_auc\": weighted_cv,\n",
    "        \"fold_scores\": fold_scores.tolist(),\n",
    "        \"n_folds\": len(folds),\n",
    "        \"params\": xgb_params,\n",
    "        \"features\": FEATURES,\n",
    "        \"validation_method\": \"GroupKFold with DT_M\",\n",
    "        \"best_iterations\": [getattr(m, 'best_iteration', None) for m in models]\n",
    "    }\n",
    "    \n",
    "    with open(\"xgboost_artifacts/xgb_metadata.json\", \"w\") as f:\n",
    "        json.dump(model_metadata, f, indent=2)\n",
    "    \n",
    "    print(f\"\\n\" + \"=\"*50)\n",
    "    print(\"KEY CHANGES MADE TO MATCH WINNER:\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"1. ✅ Used GroupKFold(n_splits=6) instead of expanding folds\")\n",
    "    print(\"2. ✅ Increased n_estimators from 2000 to 5000\") \n",
    "    print(\"3. ✅ Used groups=train['DT_M'] for temporal validation\")\n",
    "    print(\"4. ✅ Only used validation set in eval_set (not train set)\")\n",
    "    print(\"5. ✅ Calculated OOF AUC on all samples\")\n",
    "    print(\"6. ✅ Added proper memory cleanup\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n(No TransactionID in testX — skipping submission build.)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ieee-cis-fraud",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
