{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBM with GroupKFold\n",
    "import os, gc, json, pickle, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading preprocessed features...\n",
      "Train shape: (590540, 791)\n",
      "Test shape: (506691, 791)\n",
      "Features to remove: 19\n",
      "Removing 19 features\n",
      "Final feature count: 772\n",
      "['TransactionAmt', 'ProductCD', 'card1', 'card2', 'card3', 'card4', 'card5', 'card6', 'addr1', 'addr2', 'dist1', 'dist2', 'P_emaildomain', 'R_emaildomain', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11', 'C12', 'C13', 'C14', 'D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8', 'D9', 'D10', 'D11', 'D12', 'D13', 'D14', 'D15', 'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V39', 'V40', 'V41', 'V42', 'V43', 'V44', 'V45', 'V46', 'V47', 'V48', 'V49', 'V50', 'V51', 'V52', 'V53', 'V54', 'V55', 'V56', 'V57', 'V58', 'V59', 'V60', 'V61', 'V62', 'V63', 'V64', 'V65', 'V66', 'V67', 'V68', 'V69', 'V70', 'V71', 'V72', 'V73', 'V74', 'V75', 'V76', 'V77', 'V78', 'V79', 'V80', 'V81', 'V82', 'V83', 'V84', 'V85', 'V86', 'V87', 'V88', 'V89', 'V90', 'V91', 'V92', 'V93', 'V94', 'V95', 'V96', 'V97', 'V98', 'V99', 'V100', 'V101', 'V102', 'V103', 'V104', 'V105', 'V106', 'V107', 'V108', 'V109', 'V110', 'V111', 'V112', 'V113', 'V114', 'V115', 'V116', 'V117', 'V118', 'V119', 'V120', 'V121', 'V122', 'V123', 'V124', 'V125', 'V126', 'V127', 'V128', 'V129', 'V130', 'V131', 'V132', 'V133', 'V134', 'V135', 'V136', 'V137', 'V138', 'V139', 'V140', 'V141', 'V142', 'V143', 'V144', 'V145', 'V146', 'V147', 'V148', 'V149', 'V150', 'V151', 'V152', 'V153', 'V154', 'V155', 'V156', 'V157', 'V158', 'V159', 'V160', 'V161', 'V162', 'V163', 'V164', 'V165', 'V166', 'V167', 'V168', 'V169', 'V170', 'V171', 'V172', 'V173', 'V174', 'V175', 'V176', 'V177', 'V178', 'V179', 'V180', 'V181', 'V182', 'V183', 'V184', 'V185', 'V186', 'V187', 'V188', 'V189', 'V190', 'V191', 'V192', 'V193', 'V194', 'V195', 'V196', 'V197', 'V198', 'V199', 'V200', 'V201', 'V202', 'V203', 'V204', 'V205', 'V206', 'V207', 'V208', 'V209', 'V210', 'V211', 'V212', 'V213', 'V214', 'V215', 'V216', 'V217', 'V218', 'V219', 'V220', 'V221', 'V222', 'V223', 'V224', 'V225', 'V226', 'V227', 'V228', 'V229', 'V230', 'V231', 'V232', 'V233', 'V234', 'V235', 'V236', 'V237', 'V238', 'V239', 'V240', 'V241', 'V242', 'V243', 'V244', 'V245', 'V246', 'V247', 'V248', 'V249', 'V250', 'V251', 'V252', 'V253', 'V254', 'V255', 'V256', 'V257', 'V258', 'V259', 'V260', 'V261', 'V262', 'V263', 'V264', 'V265', 'V266', 'V267', 'V268', 'V269', 'V270', 'V271', 'V272', 'V273', 'V274', 'V275', 'V276', 'V277', 'V278', 'V279', 'V280', 'V281', 'V282', 'V283', 'V284', 'V285', 'V286', 'V287', 'V288', 'V289', 'V290', 'V291', 'V292', 'V293', 'V294', 'V295', 'V296', 'V297', 'V298', 'V299', 'V300', 'V301', 'V302', 'V303', 'V304', 'V305', 'V306', 'V307', 'V308', 'V309', 'V310', 'V311', 'V312', 'V313', 'V314', 'V315', 'V316', 'V317', 'V318', 'V319', 'V320', 'V321', 'V322', 'V323', 'V324', 'V325', 'V326', 'V327', 'V328', 'V329', 'V330', 'V331', 'V332', 'V333', 'V334', 'V335', 'V336', 'V337', 'V338', 'V339', 'is_december', 'is_holiday', 'card1_fq_enc', 'card2_fq_enc', 'card3_fq_enc', 'card5_fq_enc', 'uid_fq_enc', 'uid2_fq_enc', 'uid3_fq_enc', 'uid4_fq_enc', 'uid5_fq_enc', 'card3_DT_D_hour_dist', 'card3_DT_W_week_day_dist', 'card3_DT_M_month_day_dist', 'card3_DT_D_hour_dist_best', 'card3_DT_W_week_day_dist_best', 'card3_DT_M_month_day_dist_best', 'card5_DT_D_hour_dist', 'card5_DT_W_week_day_dist', 'card5_DT_M_month_day_dist', 'card5_DT_D_hour_dist_best', 'card5_DT_W_week_day_dist_best', 'card5_DT_M_month_day_dist_best', 'bank_type_DT_D_hour_dist', 'bank_type_DT_W_week_day_dist', 'bank_type_DT_M_month_day_dist', 'bank_type_DT_D_hour_dist_best', 'bank_type_DT_W_week_day_dist_best', 'bank_type_DT_M_month_day_dist_best', 'bank_type_DT_M', 'bank_type_DT_W', 'bank_type_DT_D', 'uid_D1_mean', 'uid_D1_std', 'uid2_D1_mean', 'uid2_D1_std', 'uid3_D1_mean', 'uid3_D1_std', 'uid4_D1_mean', 'uid4_D1_std', 'uid5_D1_mean', 'uid5_D1_std', 'bank_type_D1_mean', 'bank_type_D1_std', 'uid_D2_mean', 'uid_D2_std', 'uid2_D2_mean', 'uid2_D2_std', 'uid3_D2_mean', 'uid3_D2_std', 'uid4_D2_mean', 'uid4_D2_std', 'uid5_D2_mean', 'uid5_D2_std', 'bank_type_D2_mean', 'bank_type_D2_std', 'uid_D3_mean', 'uid_D3_std', 'uid2_D3_mean', 'uid2_D3_std', 'uid3_D3_mean', 'uid3_D3_std', 'uid4_D3_mean', 'uid4_D3_std', 'uid5_D3_mean', 'uid5_D3_std', 'bank_type_D3_mean', 'bank_type_D3_std', 'uid_D4_mean', 'uid_D4_std', 'uid2_D4_mean', 'uid2_D4_std', 'uid3_D4_mean', 'uid3_D4_std', 'uid4_D4_mean', 'uid4_D4_std', 'uid5_D4_mean', 'uid5_D4_std', 'bank_type_D4_mean', 'bank_type_D4_std', 'uid_D5_mean', 'uid_D5_std', 'uid2_D5_mean', 'uid2_D5_std', 'uid3_D5_mean', 'uid3_D5_std', 'uid4_D5_mean', 'uid4_D5_std', 'uid5_D5_mean', 'uid5_D5_std', 'bank_type_D5_mean', 'bank_type_D5_std', 'uid_D6_mean', 'uid_D6_std', 'uid2_D6_mean', 'uid2_D6_std', 'uid3_D6_mean', 'uid3_D6_std', 'uid4_D6_mean', 'uid4_D6_std', 'uid5_D6_mean', 'uid5_D6_std', 'bank_type_D6_mean', 'bank_type_D6_std', 'uid_D7_mean', 'uid_D7_std', 'uid2_D7_mean', 'uid2_D7_std', 'uid3_D7_mean', 'uid3_D7_std', 'uid4_D7_mean', 'uid4_D7_std', 'uid5_D7_mean', 'uid5_D7_std', 'bank_type_D7_mean', 'bank_type_D7_std', 'uid_D8_mean', 'uid_D8_std', 'uid2_D8_mean', 'uid2_D8_std', 'uid3_D8_mean', 'uid3_D8_std', 'uid4_D8_mean', 'uid4_D8_std', 'uid5_D8_mean', 'uid5_D8_std', 'bank_type_D8_mean', 'bank_type_D8_std', 'uid_D9_mean', 'uid_D9_std', 'uid2_D9_mean', 'uid2_D9_std', 'uid3_D9_mean', 'uid3_D9_std', 'uid4_D9_mean', 'uid4_D9_std', 'uid5_D9_mean', 'uid5_D9_std', 'bank_type_D9_mean', 'bank_type_D9_std', 'uid_D10_mean', 'uid_D10_std', 'uid2_D10_mean', 'uid2_D10_std', 'uid3_D10_mean', 'uid3_D10_std', 'uid4_D10_mean', 'uid4_D10_std', 'uid5_D10_mean', 'uid5_D10_std', 'bank_type_D10_mean', 'bank_type_D10_std', 'uid_D11_mean', 'uid_D11_std', 'uid2_D11_mean', 'uid2_D11_std', 'uid3_D11_mean', 'uid3_D11_std', 'uid4_D11_mean', 'uid4_D11_std', 'uid5_D11_mean', 'uid5_D11_std', 'bank_type_D11_mean', 'bank_type_D11_std', 'uid_D12_mean', 'uid_D12_std', 'uid2_D12_mean', 'uid2_D12_std', 'uid3_D12_mean', 'uid3_D12_std', 'uid4_D12_mean', 'uid4_D12_std', 'uid5_D12_mean', 'uid5_D12_std', 'bank_type_D12_mean', 'bank_type_D12_std', 'uid_D13_mean', 'uid_D13_std', 'uid2_D13_mean', 'uid2_D13_std', 'uid3_D13_mean', 'uid3_D13_std', 'uid4_D13_mean', 'uid4_D13_std', 'uid5_D13_mean', 'uid5_D13_std', 'bank_type_D13_mean', 'bank_type_D13_std', 'uid_D14_mean', 'uid_D14_std', 'uid2_D14_mean', 'uid2_D14_std', 'uid3_D14_mean', 'uid3_D14_std', 'uid4_D14_mean', 'uid4_D14_std', 'uid5_D14_mean', 'uid5_D14_std', 'bank_type_D14_mean', 'bank_type_D14_std', 'uid_D15_mean', 'uid_D15_std', 'uid2_D15_mean', 'uid2_D15_std', 'uid3_D15_mean', 'uid3_D15_std', 'uid4_D15_mean', 'uid4_D15_std', 'uid5_D15_mean', 'uid5_D15_std', 'bank_type_D15_mean', 'bank_type_D15_std', 'D9_not_na', 'D8_not_same_day', 'D8_D9_decimal_dist', 'D3_DT_D_min_max', 'D3_DT_D_std_score', 'D4_DT_D_min_max', 'D4_DT_D_std_score', 'D5_DT_D_min_max', 'D5_DT_D_std_score', 'D6_DT_D_min_max', 'D6_DT_D_std_score', 'D7_DT_D_min_max', 'D7_DT_D_std_score', 'D8_DT_D_min_max', 'D8_DT_D_std_score', 'D10_DT_D_min_max', 'D10_DT_D_std_score', 'D11_DT_D_min_max', 'D11_DT_D_std_score', 'D12_DT_D_min_max', 'D12_DT_D_std_score', 'D13_DT_D_min_max', 'D13_DT_D_std_score', 'D14_DT_D_min_max', 'D14_DT_D_std_score', 'D15_DT_D_min_max', 'D15_DT_D_std_score', 'D3_DT_W_min_max', 'D3_DT_W_std_score', 'D4_DT_W_min_max', 'D4_DT_W_std_score', 'D5_DT_W_min_max', 'D5_DT_W_std_score', 'D6_DT_W_min_max', 'D6_DT_W_std_score', 'D7_DT_W_min_max', 'D7_DT_W_std_score', 'D8_DT_W_min_max', 'D8_DT_W_std_score', 'D10_DT_W_min_max', 'D10_DT_W_std_score', 'D11_DT_W_min_max', 'D11_DT_W_std_score', 'D12_DT_W_min_max', 'D12_DT_W_std_score', 'D13_DT_W_min_max', 'D13_DT_W_std_score', 'D14_DT_W_min_max', 'D14_DT_W_std_score', 'D15_DT_W_min_max', 'D15_DT_W_std_score', 'D3_DT_M_min_max', 'D3_DT_M_std_score', 'D4_DT_M_min_max', 'D4_DT_M_std_score', 'D5_DT_M_min_max', 'D5_DT_M_std_score', 'D6_DT_M_min_max', 'D6_DT_M_std_score', 'D7_DT_M_min_max', 'D7_DT_M_std_score', 'D8_DT_M_min_max', 'D8_DT_M_std_score', 'D10_DT_M_min_max', 'D10_DT_M_std_score', 'D11_DT_M_min_max', 'D11_DT_M_std_score', 'D12_DT_M_min_max', 'D12_DT_M_std_score', 'D13_DT_M_min_max', 'D13_DT_M_std_score', 'D14_DT_M_min_max', 'D14_DT_M_std_score', 'D15_DT_M_min_max', 'D15_DT_M_std_score', 'D1_scaled', 'D2_scaled', 'TransactionAmt_check', 'card1_TransactionAmt_mean', 'card1_TransactionAmt_std', 'card2_TransactionAmt_mean', 'card2_TransactionAmt_std', 'card3_TransactionAmt_mean', 'card3_TransactionAmt_std', 'card5_TransactionAmt_mean', 'card5_TransactionAmt_std', 'uid_TransactionAmt_mean', 'uid_TransactionAmt_std', 'uid2_TransactionAmt_mean', 'uid2_TransactionAmt_std', 'uid3_TransactionAmt_mean', 'uid3_TransactionAmt_std', 'uid4_TransactionAmt_mean', 'uid4_TransactionAmt_std', 'uid5_TransactionAmt_mean', 'uid5_TransactionAmt_std', 'bank_type_TransactionAmt_mean', 'bank_type_TransactionAmt_std', 'TransactionAmt_DT_D_min_max', 'TransactionAmt_DT_D_std_score', 'TransactionAmt_DT_W_min_max', 'TransactionAmt_DT_W_std_score', 'TransactionAmt_DT_M_min_max', 'TransactionAmt_DT_M_std_score', 'product_type', 'product_type_DT_D', 'product_type_DT_W', 'product_type_DT_M', 'C1_fq_enc', 'C2_fq_enc', 'C3_fq_enc', 'C4_fq_enc', 'C5_fq_enc', 'C6_fq_enc', 'C7_fq_enc', 'C8_fq_enc', 'C9_fq_enc', 'C10_fq_enc', 'C11_fq_enc', 'C12_fq_enc', 'C13_fq_enc', 'C14_fq_enc', 'id_01', 'id_02', 'id_03', 'id_04', 'id_05', 'id_06', 'id_07', 'id_08', 'id_09', 'id_10', 'id_11', 'id_12', 'id_13', 'id_14', 'id_15', 'id_16', 'id_17', 'id_18', 'id_19', 'id_20', 'id_21', 'id_22', 'id_23', 'id_24', 'id_25', 'id_26', 'id_27', 'id_28', 'id_29', 'id_30', 'id_31', 'id_32', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38', 'DeviceType', 'DeviceInfo', 'id_33_0', 'id_33_1', 'DeviceInfo_device', 'DeviceInfo_version', 'id_30_device', 'id_30_version', 'id_31_device']\n"
     ]
    }
   ],
   "source": [
    "# LOAD DATA\n",
    "DATA_DIR = \"../data/processed\"\n",
    "\n",
    "# Load preprocessed features from kyakovlev's kernel\n",
    "print(\"Loading preprocessed features...\")\n",
    "train_df = pd.read_pickle(f\"{DATA_DIR}/train_df.pkl\")\n",
    "test_df = pd.read_pickle(f\"{DATA_DIR}/test_df.pkl\")\n",
    "remove_features_df = pd.read_pickle(f\"{DATA_DIR}/remove_features.pkl\")\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "print(f\"Features to remove: {len(remove_features_df)}\")\n",
    "\n",
    "# Get features to remove\n",
    "remove_features = list(remove_features_df['features_to_remove'].values)\n",
    "print(f\"Removing {len(remove_features)} features\")\n",
    "\n",
    "# Build final feature list (exclude removed features)\n",
    "all_features = [col for col in train_df.columns if col not in remove_features]\n",
    "\n",
    "# Exclude target and ID columns\n",
    "EXCLUDE_COLS = {'TransactionID', 'isFraud', 'DT_M'}\n",
    "FEATURES = [col for col in all_features if col not in EXCLUDE_COLS]\n",
    "\n",
    "print(f\"Final feature count: {len(FEATURES)}\")\n",
    "print(FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "USING GROUPKFOLD WITH DT_M\n",
      "============================================================\n",
      "Created 6 folds using GroupKFold\n",
      "Fold 0 withholding month 12\n",
      " rows of train = 453219, rows of holdout = 137321\n",
      "Fold 1 withholding month 15\n",
      " rows of train = 488908, rows of holdout = 101632\n",
      "Fold 2 withholding month 13\n",
      " rows of train = 497955, rows of holdout = 92585\n",
      "Fold 3 withholding month 17\n",
      " rows of train = 501214, rows of holdout = 89326\n",
      "Fold 4 withholding month 14\n",
      " rows of train = 504519, rows of holdout = 86021\n",
      "Fold 5 withholding month 16\n",
      " rows of train = 506885, rows of holdout = 83655\n",
      "\n",
      "Overall fraud rate: 0.0350 (3.50%)\n"
     ]
    }
   ],
   "source": [
    "# SETUP GROUPKFOLD\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"USING GROUPKFOLD WITH DT_M\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Use GroupKFold\n",
    "skf = GroupKFold(n_splits=6)\n",
    "folds = list(skf.split(train_df, train_df[\"isFraud\"], groups=train_df['DT_M']))\n",
    "\n",
    "print(f\"Created {len(folds)} folds using GroupKFold\")\n",
    "\n",
    "# Print fold information like the winner\n",
    "for i, (tr_idx, va_idx) in enumerate(folds):\n",
    "    month = train_df.iloc[va_idx]['DT_M'].iloc[0]\n",
    "    print(f'Fold {i} withholding month {month}')\n",
    "    print(f' rows of train = {len(tr_idx)}, rows of holdout = {len(va_idx)}')\n",
    "\n",
    "# Overall fraud rate\n",
    "overall_fraud_rate = train_df['isFraud'].mean()\n",
    "print(f\"\\nOverall fraud rate: {overall_fraud_rate:.4f} ({overall_fraud_rate*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM parameters:\n",
      "{\n",
      "  \"objective\": \"binary\",\n",
      "  \"boosting_type\": \"gbdt\",\n",
      "  \"metric\": \"auc\",\n",
      "  \"n_jobs\": -1,\n",
      "  \"learning_rate\": 0.007,\n",
      "  \"num_leaves\": 256,\n",
      "  \"max_depth\": -1,\n",
      "  \"tree_learner\": \"serial\",\n",
      "  \"colsample_bytree\": 0.5,\n",
      "  \"subsample_freq\": 1,\n",
      "  \"subsample\": 0.7,\n",
      "  \"n_estimators\": 10000,\n",
      "  \"max_bin\": 255,\n",
      "  \"verbose\": -1,\n",
      "  \"seed\": 42,\n",
      "  \"early_stopping_rounds\": 100,\n",
      "  \"force_col_wise\": true\n",
      "}\n",
      "\n",
      "============================================================\n",
      "TRAINING LIGHTGBM WITH GROUPKFOLD\n",
      "============================================================\n",
      "\n",
      "Fold 0 withholding month 12\n",
      " rows of train = 453219, rows of holdout = 137321\n",
      "[200]\ttrain's auc: 0.963837\tvalid's auc: 0.883393\n",
      "[400]\ttrain's auc: 0.987693\tvalid's auc: 0.899017\n",
      "[600]\ttrain's auc: 0.995788\tvalid's auc: 0.905981\n",
      "[800]\ttrain's auc: 0.99856\tvalid's auc: 0.910027\n",
      "[1000]\ttrain's auc: 0.999511\tvalid's auc: 0.912859\n",
      "[1200]\ttrain's auc: 0.999838\tvalid's auc: 0.914792\n",
      "[1400]\ttrain's auc: 0.999948\tvalid's auc: 0.916426\n",
      "[1600]\ttrain's auc: 0.999985\tvalid's auc: 0.91741\n",
      "[1800]\ttrain's auc: 0.999996\tvalid's auc: 0.918059\n",
      "[2000]\ttrain's auc: 0.999999\tvalid's auc: 0.918637\n",
      "[2200]\ttrain's auc: 1\tvalid's auc: 0.919353\n",
      "[2400]\ttrain's auc: 1\tvalid's auc: 0.919729\n",
      "Fold 0 AUC: 0.9198, Best iteration: 2427\n",
      "\n",
      "Fold 1 withholding month 15\n",
      " rows of train = 488908, rows of holdout = 101632\n",
      "[200]\ttrain's auc: 0.964173\tvalid's auc: 0.919799\n",
      "[400]\ttrain's auc: 0.987308\tvalid's auc: 0.934796\n",
      "[600]\ttrain's auc: 0.995698\tvalid's auc: 0.941762\n",
      "[800]\ttrain's auc: 0.998604\tvalid's auc: 0.94465\n",
      "[1000]\ttrain's auc: 0.999534\tvalid's auc: 0.946112\n",
      "[1200]\ttrain's auc: 0.999839\tvalid's auc: 0.946837\n",
      "[1400]\ttrain's auc: 0.999947\tvalid's auc: 0.9473\n",
      "[1600]\ttrain's auc: 0.999984\tvalid's auc: 0.947477\n",
      "Fold 1 AUC: 0.9475, Best iteration: 1514\n",
      "\n",
      "Fold 2 withholding month 13\n",
      " rows of train = 497955, rows of holdout = 92585\n",
      "[200]\ttrain's auc: 0.961104\tvalid's auc: 0.914554\n",
      "[400]\ttrain's auc: 0.986302\tvalid's auc: 0.930607\n",
      "[600]\ttrain's auc: 0.995333\tvalid's auc: 0.937849\n",
      "[800]\ttrain's auc: 0.998407\tvalid's auc: 0.941075\n",
      "[1000]\ttrain's auc: 0.999445\tvalid's auc: 0.942409\n",
      "[1200]\ttrain's auc: 0.999807\tvalid's auc: 0.943331\n",
      "[1400]\ttrain's auc: 0.999934\tvalid's auc: 0.944002\n",
      "[1600]\ttrain's auc: 0.99998\tvalid's auc: 0.94431\n",
      "[1800]\ttrain's auc: 0.999995\tvalid's auc: 0.944637\n",
      "Fold 2 AUC: 0.9447, Best iteration: 1842\n",
      "\n",
      "Fold 3 withholding month 17\n",
      " rows of train = 501214, rows of holdout = 89326\n",
      "[200]\ttrain's auc: 0.961531\tvalid's auc: 0.911753\n",
      "[400]\ttrain's auc: 0.985991\tvalid's auc: 0.928766\n",
      "[600]\ttrain's auc: 0.995025\tvalid's auc: 0.936532\n",
      "[800]\ttrain's auc: 0.998324\tvalid's auc: 0.940102\n",
      "[1000]\ttrain's auc: 0.999423\tvalid's auc: 0.941561\n",
      "[1200]\ttrain's auc: 0.999792\tvalid's auc: 0.942302\n",
      "[1400]\ttrain's auc: 0.999926\tvalid's auc: 0.942774\n",
      "Fold 3 AUC: 0.9428, Best iteration: 1417\n",
      "\n",
      "Fold 4 withholding month 14\n",
      " rows of train = 504519, rows of holdout = 86021\n",
      "[200]\ttrain's auc: 0.961317\tvalid's auc: 0.930153\n",
      "[400]\ttrain's auc: 0.98593\tvalid's auc: 0.94302\n",
      "[600]\ttrain's auc: 0.994942\tvalid's auc: 0.947685\n",
      "[800]\ttrain's auc: 0.998211\tvalid's auc: 0.950057\n",
      "[1000]\ttrain's auc: 0.999361\tvalid's auc: 0.951153\n",
      "[1200]\ttrain's auc: 0.999769\tvalid's auc: 0.951694\n",
      "[1400]\ttrain's auc: 0.999918\tvalid's auc: 0.951959\n",
      "[1600]\ttrain's auc: 0.999973\tvalid's auc: 0.95201\n",
      "[1800]\ttrain's auc: 0.999992\tvalid's auc: 0.952339\n",
      "Fold 4 AUC: 0.9524, Best iteration: 1851\n",
      "\n",
      "Fold 5 withholding month 16\n",
      " rows of train = 506885, rows of holdout = 83655\n",
      "[200]\ttrain's auc: 0.960633\tvalid's auc: 0.924502\n",
      "[400]\ttrain's auc: 0.985635\tvalid's auc: 0.943194\n",
      "[600]\ttrain's auc: 0.994703\tvalid's auc: 0.950752\n",
      "[800]\ttrain's auc: 0.998127\tvalid's auc: 0.954501\n",
      "[1000]\ttrain's auc: 0.999338\tvalid's auc: 0.956294\n",
      "[1200]\ttrain's auc: 0.999757\tvalid's auc: 0.957173\n",
      "[1400]\ttrain's auc: 0.99991\tvalid's auc: 0.957899\n",
      "[1600]\ttrain's auc: 0.999969\tvalid's auc: 0.958135\n",
      "[1800]\ttrain's auc: 0.999991\tvalid's auc: 0.958319\n",
      "[2000]\ttrain's auc: 0.999997\tvalid's auc: 0.958432\n",
      "Fold 5 AUC: 0.9585, Best iteration: 1916\n",
      "####################\n",
      "LGBM OOF CV = 0.9427\n",
      "\n",
      "==================================================\n",
      "LIGHTGBM CV RESULTS\n",
      "==================================================\n",
      "Fold AUCs: [0.9198 0.9475 0.9447 0.9428 0.9524 0.9585]\n",
      "Weighted mean AUC: 0.9422\n",
      "OOF AUC: 0.9427\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# LIGHTGBM PARAMETERS\n",
    "# ============================================================================\n",
    "\n",
    "# Winner's approach - parameters similar to their XGBoost but adapted for LGBM\n",
    "lgb_params = {\n",
    "    'objective': 'binary',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'metric': 'auc',\n",
    "    'n_jobs': -1,\n",
    "    'learning_rate': 0.007,\n",
    "    'num_leaves': 256,       # 2^8\n",
    "    'max_depth': -1,\n",
    "    'tree_learner': 'serial',\n",
    "    'colsample_bytree': 0.5,\n",
    "    'subsample_freq': 1,\n",
    "    'subsample': 0.7,\n",
    "    'n_estimators': 10000,\n",
    "    'max_bin': 255,\n",
    "    'verbose': -1,\n",
    "    'seed': 42,\n",
    "    'early_stopping_rounds': 100,\n",
    "    'force_col_wise': True,\n",
    "}\n",
    "\n",
    "print(\"LightGBM parameters:\")\n",
    "print(json.dumps(lgb_params, indent=2))\n",
    "\n",
    "# ============================================================================\n",
    "# TRAINING WITH GROUPKFOLD\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TRAINING LIGHTGBM WITH GROUPKFOLD\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "models = []\n",
    "oof = np.zeros(len(train_df), dtype=float)\n",
    "fold_scores, fold_sizes = [], []\n",
    "\n",
    "for fold_, (tr_idx, va_idx) in enumerate(folds):\n",
    "    month = train_df.iloc[va_idx]['DT_M'].iloc[0]\n",
    "    print(f'\\nFold {fold_} withholding month {month}')\n",
    "    print(f' rows of train = {len(tr_idx)}, rows of holdout = {len(va_idx)}')\n",
    "    \n",
    "    # Prepare data\n",
    "    X_tr, y_tr = train_df.iloc[tr_idx][FEATURES], train_df.iloc[tr_idx][\"isFraud\"]\n",
    "    X_va, y_va = train_df.iloc[va_idx][FEATURES], train_df.iloc[va_idx][\"isFraud\"]\n",
    "    \n",
    "    # Create datasets\n",
    "    tr_data = lgb.Dataset(X_tr, label=y_tr)\n",
    "    vl_data = lgb.Dataset(X_va, label=y_va)\n",
    "    \n",
    "    # Train model\n",
    "    estimator = lgb.train(\n",
    "        lgb_params,\n",
    "        tr_data,\n",
    "        valid_sets=[tr_data, vl_data],\n",
    "        valid_names=['train', 'valid'],\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=100, verbose=False),\n",
    "            lgb.log_evaluation(period=200),  # Print every 200 rounds like winner\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Predict validation set\n",
    "    oof_preds = estimator.predict(X_va, num_iteration=estimator.best_iteration)\n",
    "    oof[va_idx] = oof_preds\n",
    "    \n",
    "    # Calculate AUC\n",
    "    auc = roc_auc_score(y_va, oof_preds)\n",
    "    fold_scores.append(auc)\n",
    "    fold_sizes.append(len(va_idx))\n",
    "    \n",
    "    print(f\"Fold {fold_} AUC: {auc:.4f}, Best iteration: {estimator.best_iteration}\")\n",
    "    \n",
    "    # Store model\n",
    "    models.append(estimator)\n",
    "    \n",
    "    # Save individual fold model\n",
    "    os.makedirs(\"lgbm_artifacts\", exist_ok=True)\n",
    "    estimator.save_model(f\"lgbm_artifacts/lgbm_fold{fold_}.txt\", num_iteration=estimator.best_iteration)\n",
    "    \n",
    "    # Memory cleanup like winner\n",
    "    del X_tr, y_tr, X_va, y_va, tr_data, vl_data\n",
    "    gc.collect()\n",
    "\n",
    "# Calculate overall performance\n",
    "fold_scores = np.array(fold_scores, dtype=float)\n",
    "weights = np.array(fold_sizes, dtype=float) / np.sum(fold_sizes)\n",
    "weighted_cv = float(np.sum(fold_scores * weights))\n",
    "\n",
    "# OOF AUC\n",
    "oof_auc = roc_auc_score(train_df[\"isFraud\"], oof)\n",
    "\n",
    "print('#' * 20)\n",
    "print(f'LGBM OOF CV = {oof_auc:.4f}')\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"LIGHTGBM CV RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Fold AUCs:\", np.round(fold_scores, 4))\n",
    "print(\"Weighted mean AUC:\", f\"{weighted_cv:.4f}\")\n",
    "print(\"OOF AUC:\", f\"{oof_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved OOF predictions shape: (590540,)\n",
      "Saved model metadata\n",
      "Saved fold indices\n",
      "Saved feature importance\n",
      "\n",
      "==============================\n",
      "GENERATING SUBMISSION\n",
      "==============================\n",
      "Fold 0 test predictions: mean=0.0214, std=0.1162\n",
      "Fold 1 test predictions: mean=0.0239, std=0.1132\n",
      "Fold 2 test predictions: mean=0.0230, std=0.1147\n",
      "Fold 3 test predictions: mean=0.0254, std=0.1138\n",
      "Fold 4 test predictions: mean=0.0233, std=0.1151\n",
      "Fold 5 test predictions: mean=0.0229, std=0.1145\n",
      "Final averaged predictions: mean=0.0233, std=0.1139\n",
      "Saved submission: submissions/submission_lgbm_groupkfold_cv0.9427.csv\n",
      "Saved test predictions for ensemble\n",
      "\n",
      "============================================================\n",
      "KEY IMPROVEMENTS MADE:\n",
      "============================================================\n",
      "1. ✅ Used GroupKFold(n_splits=6) like winner\n",
      "2. ✅ Used kyakovlev's preprocessed features\n",
      "3. ✅ Applied feature removal from winner's analysis\n",
      "4. ✅ Used winner's parameter settings\n",
      "5. ✅ Matched winner's training approach\n",
      "6. ✅ Saved files for proper ensemble with XGBoost\n",
      "\n",
      "============================================================\n",
      "LGBM GROUPKFOLD COMPLETE\n",
      "============================================================\n",
      "OOF AUC: 0.9427\n",
      "This should match your XGBoost validation approach!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SAVE FOR ENSEMBLE\n",
    "# ============================================================================\n",
    "\n",
    "# 1. Save OOF predictions\n",
    "np.save(\"lgbm_artifacts/lgbm_oof_predictions.npy\", oof)\n",
    "print(f\"Saved OOF predictions shape: {oof.shape}\")\n",
    "\n",
    "# 2. Save model metadata\n",
    "model_metadata = {\n",
    "    \"model_type\": \"lightgbm_groupkfold\",\n",
    "    \"oof_auc\": oof_auc,\n",
    "    \"weighted_cv_auc\": weighted_cv,\n",
    "    \"fold_scores\": fold_scores.tolist(),\n",
    "    \"fold_weights\": weights.tolist(),\n",
    "    \"n_folds\": len(folds),\n",
    "    \"params\": lgb_params,\n",
    "    \"features\": FEATURES,\n",
    "    \"n_features\": len(FEATURES),\n",
    "    \"validation_method\": \"GroupKFold with DT_M\",\n",
    "    \"best_iterations\": [m.best_iteration for m in models],\n",
    "    \"data_source\": \"kyakovlev/ieee-fe-with-some-eda\"\n",
    "}\n",
    "\n",
    "with open(\"lgbm_artifacts/lgbm_metadata.json\", \"w\") as f:\n",
    "    json.dump(model_metadata, f, indent=2)\n",
    "print(\"Saved model metadata\")\n",
    "\n",
    "# 3. Save fold indices for reproducibility (same as XGBoost)\n",
    "fold_info = {\n",
    "    \"folds\": [(tr_idx.tolist(), va_idx.tolist()) for tr_idx, va_idx in folds],\n",
    "    \"validation_method\": \"GroupKFold\",\n",
    "    \"n_splits\": 6,\n",
    "    \"group_column\": \"DT_M\"\n",
    "}\n",
    "\n",
    "with open(\"lgbm_artifacts/lgbm_fold_indices.json\", \"w\") as f:\n",
    "    json.dump(fold_info, f, indent=2)\n",
    "print(\"Saved fold indices\")\n",
    "\n",
    "# 4. Save feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': FEATURES,\n",
    "    'importance': np.mean([m.feature_importance(importance_type='gain') for m in models], axis=0)\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "feature_importance.to_csv(\"lgbm_artifacts/lgbm_feature_importance.csv\", index=False)\n",
    "print(\"Saved feature importance\")\n",
    "\n",
    "# ============================================================================\n",
    "# GENERATE TEST PREDICTIONS AND SUBMISSION\n",
    "# ============================================================================\n",
    "\n",
    "def coerce_transaction_id(s: pd.Series) -> pd.Series:\n",
    "    if pd.api.types.is_integer_dtype(s): \n",
    "        return s.astype(\"int64\")\n",
    "    if pd.api.types.is_float_dtype(s):   \n",
    "        return s.round().astype(\"int64\")\n",
    "    if pd.api.types.is_string_dtype(s):\n",
    "        s2 = s.str.replace(r\"\\.0$\", \"\", regex=True)\n",
    "        return pd.to_numeric(s2, errors=\"raise\").astype(\"int64\")\n",
    "    return pd.to_numeric(s, errors=\"raise\").astype(\"int64\")\n",
    "\n",
    "if \"TransactionID\" in test_df.columns:\n",
    "    print(\"\\n\" + \"=\" * 30)\n",
    "    print(\"GENERATING SUBMISSION\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    test_id = coerce_transaction_id(test_df[\"TransactionID\"])\n",
    "    \n",
    "    # Average predictions across all fold models (like winner)\n",
    "    predictions = np.zeros(len(test_df))\n",
    "    \n",
    "    for i, model in enumerate(models):\n",
    "        fold_preds = model.predict(test_df[FEATURES], num_iteration=model.best_iteration)\n",
    "        predictions += fold_preds / len(models)  # Average like winner\n",
    "        print(f\"Fold {i} test predictions: mean={fold_preds.mean():.4f}, std={fold_preds.std():.4f}\")\n",
    "    \n",
    "    print(f\"Final averaged predictions: mean={predictions.mean():.4f}, std={predictions.std():.4f}\")\n",
    "    \n",
    "    # Create submission like winner's notebook\n",
    "    test_predictions_df = pd.DataFrame({\n",
    "        \"TransactionID\": test_id, \n",
    "        \"isFraud\": predictions\n",
    "    })\n",
    "    \n",
    "    # Save submission\n",
    "    os.makedirs(\"submissions\", exist_ok=True)\n",
    "    out_path = f\"submissions/submission_lgbm_groupkfold_cv{oof_auc:.4f}.csv\"\n",
    "    test_predictions_df.to_csv(out_path, index=False)\n",
    "    print(f\"Saved submission: {out_path}\")\n",
    "    \n",
    "    # Save test predictions for ensemble\n",
    "    np.save(\"lgbm_artifacts/lgbm_test_predictions.npy\", predictions)\n",
    "    print(\"Saved test predictions for ensemble\")\n",
    "    \n",
    "    # Save summary\n",
    "    summary = {\n",
    "        \"model_name\": \"lgbm_groupkfold_winner_approach\",\n",
    "        \"performance\": {\n",
    "            \"oof_auc\": oof_auc,\n",
    "            \"weighted_cv_auc\": weighted_cv,\n",
    "            \"fold_aucs\": fold_scores.tolist()\n",
    "        },\n",
    "        \"data_source\": \"kyakovlev/ieee-fe-with-some-eda\",\n",
    "        \"validation_method\": \"GroupKFold with DT_M (Winner's approach)\",\n",
    "        \"files_saved\": [\n",
    "            \"lgbm_oof_predictions.npy\",\n",
    "            \"lgbm_test_predictions.npy\", \n",
    "            \"lgbm_metadata.json\",\n",
    "            \"lgbm_fold_indices.json\",\n",
    "            \"lgbm_feature_importance.csv\"\n",
    "        ] + [f\"lgbm_fold{i}.txt\" for i in range(len(folds))],\n",
    "        \"usage_notes\": {\n",
    "            \"oof_predictions\": \"Use for stacking/blending with XGBoost and other models\",\n",
    "            \"test_predictions\": \"Ready for ensemble averaging\",\n",
    "            \"fold_models\": \"Load individual models for prediction\",\n",
    "            \"same_folds_as_xgb\": \"Use same fold indices for proper ensemble\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open(\"lgbm_artifacts/lgbm_ensemble_summary.json\", \"w\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    \n",
    "    print(f\"\\n\" + \"=\" * 60)\n",
    "    print(\"KEY IMPROVEMENTS MADE:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"1. ✅ Used GroupKFold(n_splits=6)\")\n",
    "    print(\"2. ✅ Used kyakovlev's preprocessed features\")\n",
    "    print(\"3. ✅ Applied feature removal from winner's analysis\")\n",
    "    print(\"4. ✅ Used winner's parameter settings\")\n",
    "    print(\"5. ✅ Matched winner's training approach\")\n",
    "    print(\"6. ✅ Saved files for proper ensemble with XGBoost\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n(No TransactionID in test_df — skipping submission build.)\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(\"LGBM GROUPKFOLD COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"OOF AUC: {oof_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ieee-cis-fraud",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
